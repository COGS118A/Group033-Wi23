{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Popularity of PC Video Games\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Chenxi Li (A16341810)\n",
    "- Jialong Guo (A15851883)\n",
    "- Gege Bei(A16356724)\n",
    "- Sikai Liang(A16839298)\n",
    "- Jinyi Zhao (A16315154)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. \n",
    "\n",
    "Personal Computer (PC) video games, as one of the primary forms of entertainment of the public, have long been drawing people’s attention due to their highly engaging and versatile nature. According to the latest gaming statistics, the global video game industry has accumulated a tremendous consumer base (ie. approximately 38% of the worldwide population has video gaming experiences), forming a total market size, measured by yielded revenues, of approximately $106.8 billions in 2023<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote).\n",
    "\n",
    "Moreover, the global video game industry has still been undergoing a developmental stage of rapid growth due to high market demand. The market size of the global video game industry, as the statistics indicated, is estimated to increase 9.4% over the year of 2023 and reach approximately 135 billion dollars by 2025, in which the PC gaming sector alone will accumulate around $46.7 billion<a name=\"lorenz\"></a>[<sup>[2]</sup>](#lorenznote). Through this tremendous consumer base and the capability of creating immersive, captivating worlds that enable individuals to explore various cultures and experiences, the video game industry undeniably has crucial impacts on people’s entertainment and social & cultural trends in the modern era.\n",
    "\n",
    "\n",
    "Unlike the video game market back in early 2000s where the majority sales occurred at retail stores, the digital distribution platforms, such as Steam, GamersGate, Microsoft Store, EA Origin, and so forth, have been contributing to the majority (approximately 83%) of the global video game sales nowadays<a name=\"lorenz\"></a>[<sup>[3]</sup>](#lorenznote). Steam, as the top digital distribution platform in terms of video game sales and number of users, for instance, accounts for approximately 50% to 70% of the entire PC video game downloads as well as 75% of the global vertical market<a name=\"lorenz\"></a>[<sup>[4]</sup>](#lorenznote). Such digital distribution platforms employ a series of marketing and sale strategies/practices that satisfy their active users’ demand as well as maximize their revenues and market shares. Among such business practices, building and employing a reliable, efficient model, which is capable of yielding sound estimations of popularity of video games, play an essential role in optimizing business operations. Therefore, in order to not only acquire a complete knowledge of the future development of the video game industry but also generate accurate recommendations of the products (ie. games), which ensures promising sales, it is absolutely necessary to establish an effective evaluation mechanism as mentioned above. However, predicting the popularity of the games published can be a vague and extremely difficult task due to the fact that various quantitative factors, such as the game prices, users’ playtimes, number of downloads, etc., could potentially have significant impacts on the popularity of games. Therefore, it is pivotal to predict the popularity of games based on a specified, subjective metric and incorporate the aforementioned quantitative factors in the analysis. \n",
    "\n",
    "\n",
    "Quite a few prior studies have gone on in the research area of the popularity prediction of  PC video games. The “Machine Learning for Predicting Success of Video Games,” for instance, investigates & analyzes data, which are acquired through Steam Spy (“a service that tracks the number of owners of each game” and Steam Charts (“a database that collects data about concurrent players”), including game price, supported language, price overview, reviews, and so forth (numerous data are being analyzed in this research, and those that are also involved in the analysis of this project is listed here). <sup>[5](#MichalNotes1)</sup> According to the author, success of the game is defined as  “the number of owners after two months since release for the data from Steam Spy” as well as “the average number of concurrent players in two months after release for Steam Charts”. <sup>[5](#MichalNotes1)</sup> In total, data of 9780 games are employed in the research, which are then cleaned and restructured through raw data processing. Besides, comparison between the data acquired from Steam Charts and Steam Spy is performed for further analysis. As discussed in the experiment section of this paper, the data is split into training, validation, and test set, and preprocessing dependent on these splits is then conducted individually. It is worth mentioning that cross-validation is not employed in the experiment, since it, according to the author, will lead to the issue of “predicting old games from new ones in numerous cases”.  <sup>[5](#MichalNotes3)</sup> When constructing the predictive models, the author employed regression and binary classification with three different settings “depending on the threshold where games are split (ie. >1, >10, >100 players)”: regression aims to predict a numeric value of the exact number of average concurrent players, and binary classification separates games into two categories based on the original value of “Players” (ie. a continuous class attribute running from 0 to 135300). <sup>[5](#MichalNotes4)</sup>  Five algorithms are employed in the regression stage: linear model, recursive partitioning and regression tree, random forest, Gaussian process, and support vector machine. According to the author, data splits contain 214 attributes, and Chi-squared is utilized to evaluate the importance of all attributes. Based on the average players prediction results via regression, random forest scores the best results with approximately 72% root relative squared error and 0.7 correlation, closely followed by support vector machine, which yields 74% root relative squared error and 0.7 correlation.  <sup>[5](#MichalNotes5)</sup> However, both aforementioned algorithms encounter difficulty with under-estimating games with higher numbers of average concurrent players, yet this is “ an understandable error as games may gain popularity by investing into promotions around release, attracting the interest of content creators after release etc.”  <sup>[5](#MichalNotes6)</sup> On the other hand, classification aims to detect games, which attained more average concurrent players than a certain threshold. Also, five algorithms are employed in the regression stage: recursive partitioning and regression tree, general linear model, random forest, support vector machine, and naive bayes. Based on the results, the baseline accuracy for predicting games with more than 1, 10, and 100 players on average are respectively as follows: 59.3%, 79.1%, and 95%. In predicting games with more than 100 players on average, the support vector machine scores the highest precision, closely followed by random forest, which has relatively higher recall than SVM.<sup>[5](#MichalNotes7)</sup> \n",
    "\n",
    "In conclusion, regression demonstrates a strong correlation between the average number of concurrent players and core game features. Furthermore, detecting the more successful game is possible with relatively high precision but low recall. However, the accuracy of predictions is higher for certain games yet lower for others. As a result, a subset of games that covers one third of the test data is employed through limiting it to games from publishers who released at least two games previously. The prediction of games in this subset is shown to be relatively more reliable and accurate. \n",
    "\n",
    "\n",
    "Even though this prior research focuses on the “success” of PC games released on Steam, it is still highly relevant to our project and provides us with quite a few critical insights as it employs certain data and machine learning techniques that will also be incorporated in our project. Besides, based on numerous real-world instances, “success” and “popularity” of games are highly associated with each other: those that gain high popularity among the customers often tend to be the “successful” games as defined in the aforementioned research. Our project employs a similar approach (ie. establishing an evaluation mechanism that accurately and objectively predicts the popularity of PC video games on Steam based on the estimated rating of the game), examining a collection of statistical information of the game, including the game's supportive system, required age, sale information (ie. price & discount), and customers' review information & playtime as well as the number of users who downloaded the game and employing the machine learning techniques of logistic regression, random forest, decision tree, and KNN. Through this project, we aim to facilitate the customer targeting process of the digital PC video game distribution platforms, aiding them with more time-saving, accurate user-specific video game popularity prediction algorithms, as well as provide future potential customers with objective popularity feedback. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "How can we accurately predict the rating of a new game by constructing algorithm models like logistic regression/KNN/random forest etc. based on the game's operational system, discount, player’s average playtime, average owner numbers, and the price, etc. it listed?\n",
    "\n",
    "We plan to quality the popularity of a game as reaching to the level of mostly positive in its Steam game rating record. The result should be discrete instead of continuous, as shown by the separate meanings behind each individual level. The result should also be measurable by graphing out using the classification model. The ROC curve/F1 score/precision and other metrics will likely show us the accuracy of prediction and indicate the effectiveness of our classification model. Lastly, the problem will likely be replicable since the model is dependent on time and any change on the dataset (e.g. the appearance of a new factor will likely alter the regression of our model). Predicting the popularity of a game can have several significant implications for game developers, publishers, and marketers. Creating games requires a significant investment of both time and money. By predicting the popularity of a new game, game developers and publishers can make informed choices regarding how much to spend on advertising and which features to prioritize during the development process. Estimating the potential success of a new game can offer game developers and publishers an edge over their competitors. By projecting which features or gameplay elements will be favored by players, they can design a game that distinguishes itself from other games in the market and draws in a substantial player base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metric that we chose is the confusion matrix. First, let's define the terms used in a confusion matrix:\n",
    "- True Positive (TP): The model correctly predicts that the game is popular.\n",
    "- False Positive (FP): The model incorrectly predicts that the game is popular.\n",
    "- True Negative (TN): The model correctly predicts that the game is not popular.\n",
    "- False Negative (FN): The model incorrectly predicts that the game is not popular.\n",
    "Using the confusion matrix, we can calculate several performance metrics to evaluate the model.\n",
    "\n",
    "\n",
    "- MSE: MSE stands for Mean Squared Error, it measures the average squared difference between the predicted values and the true values, and it is suitable for evaluating the performance of a regression model.\n",
    "\n",
    "- Accuracy: The proportion of correct predictions made by the model. It is calculated as (TP + TN) / (TP + FP + TN + FN).\n",
    "\n",
    "- Precision: The proportion of positive predictions that are actually true. It is calculated as TP / (TP + FP).\n",
    "\n",
    "- Recall (or Sensitivity): The proportion of actual positives that are correctly identified by the model. It is calculated as TP / (TP + FN).\n",
    "\n",
    "- F1 Score: The harmonic mean of precision and recall. It is calculated as 2 * (Precision * Recall) / (Precision + Recall).\n",
    "\n",
    "From these metrics, if the model has MSE of x, then the predictions are off by √x if  the model has an accuracy of x%, which means that x% of the predictions made by the model are correct. The precision of the model is x%, which means that when the model predicts that a game is popular, it is correct x% of the time. The recall (or sensitivity) of the model is x%, which means that the model correctly identifies x% of the popular games. The F1 Score is x%, which is the harmonic mean of precision and recall, and provides a balanced measure of the model's performance.\n",
    "\n",
    "\n",
    "In this project, we specifically focus on the F1 score, as we learned in the class, the F1 score is used to evaluate the performance of a binary classification model, which fits our model(the intended solution) perfectly, since we are trying to generate a model that could classify the popularity status of a game, and unlike other metrics, F1 scores takes both precision and recall into account, which means it is the most balanced metric among them. This is important in our case, since the false positives and false negatives are equally important. False positives in this case represents the game that is actually not popular but is classified as a popular game, which would increase the potential buyers of the game, and also increase the potential financial loss to the buyers since the game might not be worth buying; and the false negatives indicate that the game is actually a popular game but the model classified it as an unpopular game, which would potentially cause financial loss to the companies since the number of potential buyers would decrease. Therefore, the F1 score would be the best option since it could tell us how the model is performing based on these two factors(FN and FP). \n",
    "\n",
    "\n",
    "In general, a good model should have lower MSE, high accuracy, precision, and recall, and a high F1 Score. However, the choice of which metric to prioritize depends on the specific problem and the costs associated with false positives and false negatives. For example, if the cost of a false positive is higher than the cost of a false negative, then precision may be more important than recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "Dataset choice may lead to privacy concerns. The Steam dataset may contain personally identifiable information (PII) about users, such as their names, email addresses, and payment information. It is important to ensure that this data is properly anonymized and that users' privacy is protected. In order to achieve this, we carefully use the data that initially not include the private information and we also removed or anonymized them from the dataset to protect users' privacy.\n",
    "\n",
    "The output of our model maybe biased and unfair. For biasness, the Steam datasets may contain biased data, such as games that are popular only among certain demographic groups. This could lead to biased predictions, which could have negative implications for users. For fairness, our machine learning model may have the potential to unfairly discriminate against certain groups of people. For example, if the model is trained on a dataset that is biased against women, it may make unfair predictions about games that are popular among women. In order to avoid those questions, we especially remove all the variables objectivly relate to the reason that will infuence the otput of the model. For example, we removed the genre and category of the game, the nationality of the producers, the name of the producers, and the gender of the chief producers.\n",
    "\n",
    "It is important to be transparent about how the machine learning model works and how it makes predictions. Users should be informed about how their data is being used and how the model works. Users should also be given the opportunity to provide informed consent for their data to be used in the machine learning project. They should be informed about the purpose of the project and how their data will be used. Those are problems solved by Steam platform noticing the User by their comment annoucement and solved also by Kaggle cookies.\n",
    "\n",
    "We do hve a potential misuse that is hard to solve. There is a risk that the machine learning model could be misused for malicious purposes, such as predicting the popularity of games that promote hate speech or other harmful content.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
